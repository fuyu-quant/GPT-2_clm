dataset_name : 'wikitext'
dataset_config_name : None
train_file : None
validation_file : None
validation_split_percentage : 5
model_name_or_path : ''
config_name : None
tokenizer_name : None
use_slow_tokenizer : 
per_device_train_batch_size : 1
per_device_eval_batch_size : 1
learning_rate : 0.00005
weight_decay : 0.0
num_train_epochs : 3
max_train_steps : None
gradient_accumulation_steps : 1
lr_scheduler_type : "linear" #"linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"
num_warmup_steps : 0
output_dir : None
seed : 3665
model_type : None
block_size : None
preprocessing_num_workers : None
overwrite_cache : 
no_keep_linebreaks :
push_to_hub :
hub_model_id :
hub_token : 
checkpointing_steps : 
resume_from_checkpoint :
with_tracking :
